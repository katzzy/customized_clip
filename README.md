# CLIP Model Reorganization

This project is a reorganization of the CLIP model, a powerful model developed by OpenAI that connects vision and language in a unique way. The model has been restructured for easier understanding and usage.

## Project Structure

The project is organized into several Python files, each handling a different aspect of the CLIP model:

```bash
clip_model.py: PyTorch implementation code of the CLIP model
clip_transform.py: Image transformation code for the CLIP model
clip_tokenize.py: Text tokenization code for the CLIP model
```

## Requirements

Waiting to add

## Note

This project assumes that you have a CUDA-compatible GPU. If not, it will default to using the CPU.
